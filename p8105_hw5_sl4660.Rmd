---
title: "p8105_hw5_sl4660"
author: "Sibei Liu"
date: "2019/11/10"
output: github_document
---

```{r setup}
knitr::opts_chunk$set(set.seed(10))
```

# Problem 1
```{r,message=FALSE,warning=FALSE}
library(tidyverse)
library(ggrepel)


iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()
```



```{r}

fill_missing= function(x) {
  
  if (is.numeric(x)){
  replace_na(x,mean(x,na.rm=TRUE))
  } else if(is.character(x)){
    replace_na(x,"virginica")
  }    
}

iris_without_missing= iris_with_missing %>% 
  map(fill_missing) %>% 
  bind_cols() %>%  
  knitr::kable(digit=3)

iris_without_missing
```

The table after filling missing values is shown above

# Problem 2

```{r}
data_total=list.files("./data")
data_total=str_c("./data/",data_total)
```

```{r,message=FALSE,warning=FALSE}
data_total=list.files("./data") %>%
  tibble()  %>% 
  rename(file_name=".") %>% 
  mutate(
   detail= map(data_total,read_csv) 
  ) 

data_total
```


```{r,message=FALSE,warning=FALSE}
cleaned_data=data_total %>% 
separate(col=file_name,into=c("type","id"),sep="_")%>%
  mutate(id = gsub("\\.csv", "",id )) %>% 
  unnest() %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week_time",
    values_to = "data"
  ) 

cleaned_data
```


```{r}
ggplot(cleaned_data,aes(x=week_time,y=data,color=id,group=id))+geom_point()+geom_line()+facet_grid(~type)+theme(axis.text.x = element_text(angle = 60, hjust=1))
```

Comment: In control group, the lines are fluctuating.The data dosen't change a lot when time increases While in the experinment group, the genereal trend is upward. While the time increase, the data increases.

# Problem 3
when $\beta_1$=0
```{r}
sim_regression = function(n=30, beta0=2, beta1){
  
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, sd=sqrt(50))
  )
  
   lm(y ~ x, data = sim_data) %>% 
    broom:: tidy() %>% 
  filter(term=="x")  %>% 
  select(estimate,p.value) %>% 
  rename(beta1_hat="estimate") %>% 
  mutate(
    beta1_true=beta1
  ) 
}
output=rerun(10000,sim_regression(beta1=0)) %>% 
  bind_rows()
output
```

```{r}
beta1_list = list("beta1_1"  = 1, 
              "beta1_2"  = 2, 
              "beta1_3" = 3, 
              "beta1_4" = 4,
              "beta1_5" = 5,
              "beta1_6" = 6
              )

output2 = vector("list", length = 6)

for(i in 1:6) {
  output2[[i]] = rerun(10000, sim_regression(beta1=beta1_list[[i]])) %>% 
    bind_rows()
} 

output_final=output2 %>% bind_rows() 
  
output_final
```

# First
```{r,message=FALSE,warning=FALSE}
output_final %>% 
  mutate(
   significance = case_when(
      p.value < 0.05 ~ "sig",
      p.value >=0.05 ~ "not_sig",
      TRUE     ~ ""
  )
  ) %>% 
  filter(significance=="sig") %>% 
  group_by(beta1_true) %>% 
  summarise(n=n()) %>% 
  mutate(
    n_total=10000,
    pro=n/n_total
  ) %>% ggplot(aes(x=beta1_true,y=pro))+geom_point()+geom_smooth(se=FALSE)+geom_text_repel(aes(label=pro))+labs(
    x = "True beta1",
    y = "proportion of times the null was rejected(Power)"
  ) +geom_smooth(se=FALSE)

```

Comment: The effect size increases, the power increases.

# Second
```{r,,message=FALSE,warning=FALSE}
output_final %>% 
  group_by(beta1_true)  %>% 
  summarise(ave_beta1_hat=round(mean(beta1_hat),5)) %>% 
   ggplot(aes(x=beta1_true,y=ave_beta1_hat))+geom_point()+geom_text_repel(aes(label=ave_beta1_hat))+labs(
    x = "True beta1",
    y = "Mean of estimated beta1"
  )+geom_smooth(se=FALSE)
  
```

```{r,,message=FALSE,warning=FALSE}
output_final %>% 
  mutate(
   significance = case_when(
      p.value < 0.05 ~ "sig",
      p.value >=0.05 ~ "not_sig",
      TRUE     ~ ""
  )
  ) %>% 
  filter(significance=="sig") %>% 
  group_by(beta1_true)  %>% 
  summarise(ave_beta1_hat=round(mean(beta1_hat),5)) %>% 
   ggplot(aes(x=beta1_true,y=ave_beta1_hat))+geom_point()+geom_text_repel(aes(label=ave_beta1_hat))+labs(
    x = "True beta1",
    y = "Mean of estimated beta1 in significant cases"
  )+geom_smooth(se=FALSE)
  
```

They are not equal. When beta 1 increase, the power would increase, which means the ability to reject the null increases. So when beta1=6, whose power is greatest, the more null valuse would be rejected. So, the average estimate of Î²^1 in significant samples is closer to the true beta1.
